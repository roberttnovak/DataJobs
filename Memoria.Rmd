---
title: "PRA2 - Tipologia y Ciclo de Vida de los Datos"
author: "Geovanny Risco y Robert Novak"
date: "3/1/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=F, fig.align = 'center', warning=F)
```

```{r, echo=FALSE, message=F, warning=F}
library(tidyverse)
library(readr)
library(car)
raw_data <- read_csv("Data/Raw/uncleaned_data.csv")
cols_raw_data <- names(raw_data)
cols_no_interest <- c("index","Job Description") #Eliminamos Job Description de momento por tener demasiada información
cols_raw_data_filtered <- cols_raw_data[-which(cols_raw_data %in% cols_no_interest)]
clean_data <- raw_data

# Asignamos el valor NA en todas las celdas de la tabla donde aparece un -1 o un Unknown
# Esto lo podemos hacer porque entre las variables numéricas que tenemos no hay ninguna en la que en su dominio tenga valores negativos
clean_data[clean_data==-1 | clean_data=="Unknown" | clean_data=="Unknown / Non-Applicable"] <- NA

data_jobs_titles <- "data scientist|data engineer|data analyst|machine learning" 

# Tratamos el nombre de los trabajos para considerar idénticos aquellos que tienen mínimas variaciones
clean_data <- clean_data %>% 
  mutate(`Job Title`= tolower(`Job Title`) %>% 
           str_extract(data_jobs_titles)
         )
clean_data <- clean_data[!is.na(clean_data$`Job Title`),]
clean_data <- clean_data %>% 
  separate(`Salary Estimate`,sep="-", into=c("Salary Estimate Inf","Salary Estimate Sup")) %>%
  mutate(
    `Salary Estimate Inf` = gsub("K|\\$","",`Salary Estimate Inf`),
    `Salary Estimate Sup` = gsub("K|\\$","",`Salary Estimate Sup`) 
  ) %>% 
  #Lo separamos de nuevo para evitar poner todas las variaciones posibles Glassdoor est., Employer Est. etc
  separate(`Salary Estimate Sup`, sep="\\(", into=c("Salary Estimate Sup", "drop")) %>% 
  select(-drop ) %>% 
  mutate(
    `Salary Estimate Inf` = as.double(`Salary Estimate Inf`),
    `Salary Estimate Sup` = as.double(`Salary Estimate Sup`),
    `Salary Estimate Med` = (`Salary Estimate Inf` + `Salary Estimate Sup`)/2
  )
clean_data <- clean_data %>% 
  mutate(`Company Name`=str_remove_all(`Company Name`,"\n.*"))
clean_data <-  clean_data %>% 
  mutate(`Same Location Headquarter`= Location==Headquarters)
clean_data <- clean_data %>% 
  mutate(
    `Size Ordered`=
           case_when(
             Size=="1 to 50 employees"              ~ 1,
             Size=="51 to 200 employees"            ~ 2,
             Size=="201 to 500 employees"           ~ 3,
             Size=="501 to 1000 employees"          ~ 4,
             Size=="1001 to 5000 employees"         ~ 5,
             Size=="5001 to 10000 employees"        ~ 6,
             Size=="10000+ employees"               ~ 7,
         ),
    Size=
      case_when(
             Size=="1 to 50 employees"              ~ "1-50",
             Size=="51 to 200 employees"            ~ "51-200",
             Size=="201 to 500 employees"           ~ "201-500",
             Size=="501 to 1000 employees"          ~ "501-1000",
             Size=="1001 to 5000 employees"         ~ "1001-5000",
             Size=="5001 to 10000 employees"        ~ "5001-10000",
             Size=="10000+ employees"               ~ "10000-Inf",
         )
         
) %>% 
  separate(Size, sep="-", into=c("Size Inf","Size Sup")) %>% 
  mutate(
    `Size Inf`=as.numeric(`Size Inf`),
    `Size Sup`=as.numeric(`Size Sup`)
  )

clean_data <- clean_data %>% 
  mutate(
    `Revenue Ordered`=
           case_when(
             Revenue=="Less than $1 million (USD)"       ~ 1,
             Revenue=="$1 to $5 million (USD)"           ~ 2,
             Revenue=="$5 to $10 million (USD)"          ~ 3,
             Revenue=="$10 to $25 million (USD)"         ~ 4,
             Revenue=="$25 to $50 million (USD)"         ~ 5,
             Revenue=="$50 to $100 million (USD)"        ~ 6,
             Revenue=="$100 to $500 million (USD)"       ~ 7,
             Revenue=="$500 million to $1 billion (USD)" ~ 8,
             Revenue=="$1 to $2 billion (USD)"           ~ 9,
             Revenue=="$2 to $5 billion (USD)"           ~ 10,
             Revenue=="$5 to $10 billion (USD)"          ~ 11,
             Revenue=="$10+ billion (USD)"               ~ 12 
         ),
    Revenue=
           case_when(
             Revenue=="Less than $1 million (USD)"       ~ "0-1000000",
             Revenue=="$1 to $5 million (USD)"           ~ "1000000-5000000",
             Revenue=="$5 to $10 million (USD)"          ~ "5000000-10000000",
             Revenue=="$10 to $25 million (USD)"         ~ "10000000-25000000",
             Revenue=="$25 to $50 million (USD)"         ~ "25000000-50000000",
             Revenue=="$50 to $100 million (USD)"        ~ "50000000-100000000", 
             Revenue=="$100 to $500 million (USD)"       ~ "100000000-500000000",
             Revenue=="$500 million to $1 billion (USD)" ~ "500000000-1000000000",
             Revenue=="$1 to $2 billion (USD)"           ~ "1000000000-2000000000",
             Revenue=="$2 to $5 billion (USD)"           ~ "2000000000-5000000000",
             Revenue=="$5 to $10 billion (USD)"          ~ "5000000000-10000000000",
             Revenue=="$10+ billion (USD)"               ~ "10000000000-Inf",
         )
         
) %>% 
  separate(Revenue, sep="-", into=c("Revenue Inf","Revenue Sup")) %>% 
  mutate(
    `Revenue Inf`=as.numeric(`Revenue Inf`),
    `Revenue Sup`=as.numeric(`Revenue Sup`)
  )
```

\newpage

# Descripción del Dataset

```{r, echo=F}
cols_raw_data
```


El dataset que hemos escogido está recogido mediante webscraping en distintas plataformas sobre ofertas de empleo relacionadas con los datos en Estados Unidos. Hemos escogido este dataset principalmente por dos razones.

1. Es un dataset bastante desordenado en el que da lugar a hacer procesos de limpieza de distinto tipo ideal para asentar los conceptos tratados en la asignatura

1. Nos parece interesante conocer el mercado laboral de las distintas profesiones a las que podríamos aspirar tras la finalización del máster y la demanda, aunque sea en un país extranjero.

Nuestro principal objetivo con el dataset es contestar a distintas preguntas relacionadas con el salario y distintas variables que se proporcionan en el dataset: 

\#**TODO**: Aquí concretar un poco algunas de ellas


# Integración y selección de los datos de interés a analizar 

En primer lugar, hemos realizado un análisis del dominio de las variables a partir de las cuáles hemos hecho hecho las siguientes observaciones:

1. Se utiliza el `-1` para indicar valores faltantes. Adicionalmente, existen columnas que tienen un valor faltante que se representa de forma distinta a `-1` por la forma en la que se han extraído los datos. En la limpieza hemos tratado todos esos casos y representado los valores faltantes de forma homogénea mediante `NA`, que es la forma de representar los valores faltantes en R y gracias al cuál podemos hacer operaciones para algunas de las funciones donde se tienen en cuenta los valores faltantes. 

1. La columna `Job title` tiene una gran diversidad de trabajos con una mínima variación en la que es interesante tratarlos como un mismo trabajo. Para ello, hemos definido un subconjunto de trabajos a partir del cuál tratar como iguales las variantes. Ese subconjunto son los que consideramos principales : \{ data scientist, data engineer, data analyst, machine learning\}. Así, por ejemplo, un trabajo de e-commerce data analyst o uno de RFP data analyst será tratado bajo la categoría de data analyst. Aquellos trabajos muy específicos en los cuáles no se engloba bajo ninguna de las categorías anteriores los consideramos muy específicos y, al no ser un número muy elevado hemos decidido eliminarlos del dataset. 

1. La variable `Company name` tiene la información del rating. Hemos eliminado esa redundancia

1. Hemos añadido una nueva variable binaria a partir de `Location` y `Headquarters` para ver aquellas ofertas de trabajo en la que la cede central de la empresa está en el mismo sitio que la oferta 

1. Algunas variables como `Salary Estimate`, `Size` y `Revenue` contienen información que pueden ser aprovechadas mejor separándolas en más columnas a partir de las cuáles sacar más información. Así, las hemos separado en más columnas. Una para los rangos mínimos, otro para los rangos máximos y otra para los medios. 

1. `Salary Estimate` puede ser considerada una variable cuantitativa ya que, aunque se proporcione un rango  variable para todas las ofertas, la realidad es que el salario no es un rango sino un valor concreto dado por un dominio continuo. La decisión que hemos tomado para solucionar esto es considerar el punto medio del rango proporcionado como el salario de la oferta. Esta solución es una aproximación ya que dos ofertas con mismos rangos tendrían el mismo salario y no tendría por qué ser considerados como el mismo. O, incluso, dos salarios con rangos distintos pero con una cierta intersección podrían tener en la realidad el mismo salario pero no tal como lo hemos tratado. Sin embargo, aunque lo ideal sería hacer un estudio externo sobre la distribución del salario dado el rango, la empresa particular, etc. Al no disponer de esa información asumimos esta simplificación. 

1. `Size` y `Revenue` deben ser consideradas para análisis posteriores como variables ordinales ya que su dominio corresponde a categorías no solapadas en el que el orden importa.

1. La variable `Job Description` es una variable muy interesante a partir de la cuál se puede obtener información interesante como, por ejemplo, los lenguajes de programación exigidos por la oferta, los años de experiencia necesario, etc. Sin embargo, esta información está presente de forma muy variable de observación en observación lo que hace difícil su extracción para los conocimientos que tenemos actualmente (aún no hemos tenido ninguna asignatura de NLP). Por ello, hemos decidido no tratarla más que para comprobar casos atípicos por si hay alguna información interesante que pudiera explicarlos.


\#**TODO**: Subselección de las variabels de interés (No): 

* Rating 
* index
* competitors
* founded

# Limpieza de datos 

## Tratamiento de los valores nulos de la varialble de interés `Salary Estimate Med`

\#**TODO**

## Tratamiento de los valores extremos de la variable de interés `Salary Estimate Med`

```{r, echo=F, results=F}
salary_outliers <- unique(boxplot.stats(clean_data$`Salary Estimate Med`)$out)
salary_outliers
```

```{r, echo=F, results=F}
boxplot(clean_data$`Salary Estimate Med`, main="Salario estimado promedio", col="blue")
```

En el análisis que hemos realizado, hemos observado que  la variable `Salary Estimate Med` tiene una distribución de valores bastante consistente, lo cual podemos comprobar dado el pequeño tamaño de su rango intercuartílico. No obstante, vemos como existen puntos fuera de este rango y de los *whiskers*, los conocidos como *outliers*. En concreto, son dos puntos: `r salary_outliers[1]` y `r salary_outliers[2]`. 

Explorando los casos en el que el salario es atípicamente bajo hemos encontrado que se corresponde con posiciones en las que no se piden experiencia (lo podemos comprobar por la variable `Job Description`) y, además, se encuentran en ciudades de Estados Unidos poco punteras (tecnologicamente hablando), como por ejemplo "Lincoln", "Arlington", "Saint Paul", etc. Por tanto, podemos concluir que estas variables no se tratan de errores en el dataset, sino de valores totalmente legítimos que debemos tener en cuenta para las pruebas estadísticas posteriores. 

En el caso del valor atípico alto podemos observar lo contrario, estas observaciones están asociadas a:

  * Posiciones para managers, seniors o PhDs. Es decir, se requiere formación y experiencia para optar a este sueldo 
  * Ciudad muy punteras en el ambito tecnológico. Ex. "Seattle", "New York", "Washington", etc.
  * Empresas muy top. Ex. "Roche", "Aztrazeneca", "Maxar Technologies", etc.

Dado que estos salarios tan altos son totalmente justificables (por las razones planteadas, entre otras), hemos mantenido los registros para las pruebas estadísticas posteriores. 


# Análisis de datos 

Para el análisis nos interesa la relación existente entre las distintas variables del dataset con la variable `Salary`. Las pruebas estadísticas que se aplicarán dependerán del análisis de la normalidad de `Salary Estimate Med`

## Comprobación de normalidad de la variable `Salary Estimate Med`

La variable `Salary Estimate Med` representa la variable cuantitativa de interés según lo explicado en el apartado de limpieza de datos. 

A continuación proporcionamos dos gráficas para comprobar visualmente, previo al test de normalidad, si la variable tiene apariencia de ser normal.

```{r, echo=F, results=F}
n_bins<- clean_data %>% 
  distinct(`Salary Estimate Med`) %>% 
  as_vector() %>% 
  length()
```


```{r, echo=F}
clean_data %>% 
  ggplot(aes(x=`Salary Estimate Med`)) +
  geom_histogram(bins=n_bins, fill="lightblue",color="black") +
  theme_bw() +
  scale_x_continuous(breaks=scales::pretty_breaks(n = 10)) +
  scale_y_continuous(breaks=scales::pretty_breaks(n = 10)) +
  labs(x="Salario medio estimado", y="Conteo")
```


```{r, echo=F}
clean_data %>% 
  ggplot(aes(x=`Salary Estimate Med`)) +
  geom_density(alpha=0.6, fill="lightblue") +
  theme_bw() +
  scale_x_continuous(breaks=scales::pretty_breaks(n = 10)) +
  scale_y_continuous(breaks=scales::pretty_breaks(n = 10)) +
  labs(x="Salario medio estimado", y="Probabilidad")
```

```{r, echo=F}
p_value_normality <- shapiro.test(clean_data$`Salary Estimate Med`)$p.value
```


En vista de los gráficos se puede apreciar que no parece que la distribución del salario sea normal. Comprobándolo de manera formal con el test de shapiro, el pvalor es `r p_value_normality`.  El p valor es muy bajo por lo que se puede rechazar la hipótesis nula de que la variable sigue una distribución normal. Hay que tener en cuenta este hecho para los análisis que presupongan normalidad

## Comprobación de homocedasticidad de la variable `Salary Estimate Med`

\#TODO

## Pruebas estadísticas

### Análisis entre las variables categóricas `Job Title`, `Size Ordered`, `Revenue Ordered`, `Industry` y la variable cuantitativa `Salary Estimate Med`

A continuación, vamos a comprobar las diferencias entre los distintos grupos existentes en el dataset. 

La cuestión principal es **¿Existen diferencias salariales significativas entre los distintos trabajos que hemos definido?** 


Si representamos esto gráficamente, se puede apreciar que los salarios se distribuyen de forma bastante uniforme:

```{r, echo=F}
clean_data %>% 
  ggplot(aes(y=`Salary Estimate Med`, fill=`Job Title`)) +
  scale_x_continuous(labels=NULL) +
  scale_y_continuous(breaks=scales::pretty_breaks(n = 10)) +
  theme_classic() +
  geom_boxplot()
```


De la misma manera, sería interesante observar las diferencias entre los salarios para cada una de las industrias disponibles en el dataset. Dado que existen más de 50 valores diferentes para la variable de `Industry`, procederemos a representar al menos las 7 primeras industrias con más concurrencia en el dataset. 


```{r, fig.align = 'left'}
clean_data %>%
  filter(!is.na(Industry)) %>%
  add_count(Industry) %>%
  arrange(desc(n)) %>% # igual a add_count(Industry,sort=T)
  slice_max(n, prop=0.5) %>%
  ggplot(aes(x=Industry, y=`Salary Estimate Med`)) + geom_bar(stat="summary", fun="mean", fill="steelblue")+coord_flip()+theme_classic()

```


A simple vista no observamos diferencias considerables entre los salarios medios para cada una de las industrias mostradas en el gráfico. Vemos como casi todas ofrecen salarios cercanos a los 125.000\$. La industria aeroespacial es la que mejor pagada, superando los 150.000\$ anuales.



```{r}
levene_job <- leveneTest(`Salary Estimate Med` ~ `Job Title` , data=clean_data )$`Pr(>F)`[1]
levene_size <- leveneTest(`Salary Estimate Med` ~ as.factor(`Size Ordered`) , data=clean_data )$`Pr(>F)`[1]
levene_revenue <- leveneTest(`Salary Estimate Med` ~ as.factor(`Revenue Ordered`) , data=clean_data )$`Pr(>F)`[1]
levene_industry <- leveneTest(`Salary Estimate Med` ~ `Industry` , data=clean_data )$`Pr(>F)`[1]
```
Vamos a comprobar lo visto anteriormente de manera formal. Para ello, hemos comrpobado, en primer lugar, la homocedasticidad mediante el test de levene para todas las variables de interés. Los resultados han sido `r levene_job`,  `r levene_size`, `r levene_revenue` y `r levene_industry` para `Job Title`, `Size Ordered`, `Revenue Ordered`, `Industry` respectivamente. Es decir, en todos los casos no podemos rechazar la hipótesis nula de que las varianzas poblacionales son iguales. Por tanto, podemos aplicar el test de Kruskal en el cual no hace falta que las distribuciones provengan de la normal pero sí asume la homocedasticidad. 

```{r, echo = F, warning=F}
tabla_resumen <- tibble(
  "Job Title" = levene_job,
  "Size"      = levene_size,
  "Revenue"   = levene_revenue, 
  "Industry"  = levene_industry
)
tabla_resumen %>% knitr::kable()
```


```{r, echo=F, warning=F}
kruskal_job <- kruskal.test(`Salary Estimate Med` ~ `Job Title`, data = clean_data)$p.value
kruskal_size <- kruskal.test(`Salary Estimate Med` ~ `Size Ordered`, data = clean_data)$p.value
kruskal_revenue <- kruskal.test(`Salary Estimate Med` ~ `Revenue Ordered`, data = clean_data)$p.value
kruskal_industry <- kruskal.test(`Salary Estimate Med` ~ Industry, data = clean_data)$p.value
```


El test de Kruskal es un test no paramétrico cuya hipótesis inicial es que todas las muestras provienen de la misma distribución. Mediante él, hemos comprobado formalmente que esto efectivamente es así, pues los p valores son los mostrados en la tabla resumen de a continuación: 

```{r echo=F, warning=F}
tabla_resumen <- tibble(
  "Job Title"= kruskal_job,
  "Size"= kruskal_size,
  "Revenue"= kruskal_revenue, 
  "Industry"= kruskal_industry
)
tabla_resumen %>% knitr::kable()
```


### Análisis de correlación entre `Rating` y `Salary Estimate Med`

```{r echo=F}
corr <- cor(clean_data$Rating, clean_data$`Salary Estimate Med`, method="spearman", use="complete.obs")
```

Otra cuestión de interés es si a partir del rating se puede predecir el salario. Para ver si la calidad de la oferta está relacionada con el salario o quizás intervengan más factores. La relación entre las dos variables se puede ver en el siguiente gráfico:  

```{r, echo=F, warning=F}
clean_data %>% 
  ggplot(aes(x=Rating,y=`Salary Estimate Med`)) +
  geom_point()
```


La correlación de Spearman que nos ha salido entre estas dos variables es de `r corr`. Es decir, no parece que estén correlacionadas. 


\#**TODO**: regresión


# Resolución del problema. 




